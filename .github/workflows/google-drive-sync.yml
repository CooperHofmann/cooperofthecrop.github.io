name: Google Drive Image Sync

on:
  repository_dispatch:
    types: [sync-google-drive-images]
  workflow_dispatch:
    inputs:
      folder_link:
        description: 'Google Drive folder link'
        required: true
        type: string
      category:
        description: 'Category (track/soccer/football/basketball/best-of)'
        required: true
        type: string

permissions:
  contents: write

jobs:
  sync-images:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests Pillow beautifulsoup4
      
      - name: Extract folder ID from link
        id: extract_id
        run: |
          # Extract folder ID from various Google Drive URL formats
          FOLDER_LINK="${{ github.event.client_payload.folder_link || github.event.inputs.folder_link }}"
          echo "Input folder link: $FOLDER_LINK"
          
          # Validate input to prevent command injection
          if [[ ! "$FOLDER_LINK" =~ ^[a-zA-Z0-9_/:.?=-]+$ ]]; then
            echo "Error: Invalid characters in folder link"
            exit 1
          fi
          
          # Pattern 1: https://drive.google.com/drive/folders/FOLDER_ID
          if [[ $FOLDER_LINK =~ /folders/([a-zA-Z0-9_-]+) ]]; then
            FOLDER_ID="${BASH_REMATCH[1]}"
          # Pattern 2: https://drive.google.com/drive/u/0/folders/FOLDER_ID
          elif [[ $FOLDER_LINK =~ /u/[0-9]+/folders/([a-zA-Z0-9_-]+) ]]; then
            FOLDER_ID="${BASH_REMATCH[1]}"
          # Pattern 3: Direct folder ID
          elif [[ $FOLDER_LINK =~ ^[a-zA-Z0-9_-]+$ ]]; then
            FOLDER_ID="$FOLDER_LINK"
          else
            echo "Error: Could not extract folder ID from link"
            exit 1
          fi
          
          # Validate extracted folder ID format
          if [[ ! "$FOLDER_ID" =~ ^[a-zA-Z0-9_-]+$ ]]; then
            echo "Error: Invalid folder ID format"
            exit 1
          fi
          
          echo "folder_id=$FOLDER_ID" >> $GITHUB_OUTPUT
          echo "Extracted folder ID: $FOLDER_ID"
      
      - name: Download images from Google Drive
        id: download
        env:
          FOLDER_ID: ${{ steps.extract_id.outputs.folder_id }}
          CATEGORY: ${{ github.event.client_payload.category || github.event.inputs.category }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import io
          import json
          import re
          import requests
          from bs4 import BeautifulSoup
          from PIL import Image
          from urllib.parse import parse_qs, urlparse
          
          folder_id = os.environ['FOLDER_ID']
          category = os.environ['CATEGORY']
          
          # Map category to directory name
          category_map = {
              'track': 'track',
              'soccer': 'soccer',
              'football': 'football',
              'basketball': 'basketball',
              'best-of': 'best-of'
          }
          
          if category not in category_map:
              print(f"Error: Invalid category '{category}'")
              exit(1)
          
          target_dir = f"images/{category_map[category]}"
          os.makedirs(target_dir, exist_ok=True)
          
          print(f"Downloading images from public folder {folder_id} to {target_dir}")
          print("✨ Using FREE public folder access - No credit card or service account required!")
          
          # Function to get files from public Google Drive folder
          def get_public_drive_files(folder_id):
              """Get list of files from a public Google Drive folder using web scraping"""
              url = f"https://drive.google.com/drive/folders/{folder_id}"
              
              # Make request with proper headers
              headers = {
                  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
              }
              
              try:
                  response = requests.get(url, headers=headers)
                  response.raise_for_status()
                  
                  # Parse the HTML to extract file information
                  html_content = response.text
                  
                  # Extract data from the page - Google Drive embeds file info in JSON
                  # Look for the data structure that contains file information
                  files = []
                  
                  # Pattern to find file IDs in the HTML (they appear in various formats)
                  id_pattern = r'"([a-zA-Z0-9_-]{25,})"'
                  potential_ids = set(re.findall(id_pattern, html_content))
                  
                  # Filter to only include what looks like file IDs (not folder IDs or other data)
                  # File IDs in the folder view typically appear with specific markers
                  file_marker_pattern = r'\["([a-zA-Z0-9_-]{25,})"[,\]]'
                  file_ids = re.findall(file_marker_pattern, html_content)
                  
                  # Also try to get file names if possible
                  name_pattern = r'"([^"]+\.(?:jpg|jpeg|png|gif|webp|bmp))"'
                  file_names = re.findall(name_pattern, html_content, re.IGNORECASE)
                  
                  if file_ids:
                      print(f"Found {len(file_ids)} potential file(s) in the folder")
                      # Create file objects - use unique file IDs
                      unique_ids = list(set(file_ids[:20]))  # Limit to first 20 unique IDs, preserve as list
                      unique_names = list(set(file_names[:len(unique_ids)]))  # Get unique names too
                      
                      for i, file_id in enumerate(unique_ids):
                          # Use corresponding name if available, otherwise generate one
                          name = unique_names[i] if i < len(unique_names) else f"image_{i+1}.jpg"
                          files.append({
                              'id': file_id,
                              'name': name
                          })
                  else:
                      print("Warning: Could not find file IDs in folder. The folder might be:")
                      print("  - Empty")
                      print("  - Not publicly shared")
                      print("  - Using a different format")
                  
                  return files
                  
              except requests.exceptions.RequestException as e:
                  print(f"Error accessing folder: {str(e)}")
                  print("\nMake sure:")
                  print("  1. The folder link is correct")
                  print("  2. The folder is shared as 'Anyone with the link can view'")
                  print("  3. The folder contains image files")
                  return []
          
          def download_public_file(file_id, output_path):
              """Download a file from Google Drive using public direct download"""
              # Try multiple download methods
              
              # Method 1: Direct download URL
              download_url = f"https://drive.google.com/uc?export=download&id={file_id}"
              
              headers = {
                  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
              }
              
              try:
                  response = requests.get(download_url, headers=headers, stream=True, timeout=30)
                  
                  # Check content type first before loading entire response
                  content_type = response.headers.get('content-type', '')
                  
                  # Check if we got a confirmation page (large files) - only check if it's HTML
                  if 'text/html' in content_type:
                      # Only load text for HTML responses
                      page_content = response.text
                      if 'confirm=' in page_content or 'download_warning' in page_content:
                          # Extract confirmation token
                          soup = BeautifulSoup(page_content, 'html.parser')
                          confirm_link = soup.find('a', {'id': 'uc-download-link'})
                          
                          if confirm_link and 'href' in confirm_link.attrs:
                              confirm_url = "https://drive.google.com" + confirm_link['href']
                              response = requests.get(confirm_url, headers=headers, stream=True, timeout=30)
                              content_type = response.headers.get('content-type', '')  # Update content type
                  
                  if response.status_code == 200:
                      # Content type already checked above
                      if 'image' in content_type or 'octet-stream' in content_type:
                          return response.content
                      else:
                          # Try to load it as image anyway (some servers don't set correct content-type)
                          return response.content
                  
                  return None
                  
              except Exception as e:
                  print(f"  Error during download: {str(e)}")
                  return None
          
          # Get files from the public folder
          files = get_public_drive_files(folder_id)
          
          if not files:
              print("\n" + "="*60)
              print("NO FILES FOUND")
              print("="*60)
              print("\nTo use this FREE method (no credit card needed):")
              print("1. Right-click your Google Drive folder")
              print("2. Select 'Share' > 'Get link'")
              print("3. Change to 'Anyone with the link' can VIEW")
              print("4. Copy and use that link")
              print("\n✨ This method is 100% free - no Google Cloud account needed!")
              print("="*60)
              
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"file_count=0\n")
                  f.write(f"status=no_files\n")
              exit(0)
          
          print(f"Found {len(files)} file(s) to download")
          
          downloaded_files = []
          failed_files = []
          
          for file_info in files:
              file_id = file_info['id']
              file_name = file_info['name']
              
              print(f"Downloading: {file_name} (ID: {file_id})")
              
              try:
                  # Download file
                  file_content = download_public_file(file_id, target_dir)
                  
                  if not file_content:
                      print(f"  ✗ Could not download file")
                      failed_files.append(file_name)
                      continue
                  
                  # Open with PIL to verify it's a valid image
                  try:
                      img = Image.open(io.BytesIO(file_content))
                      
                      # Image compression settings (match admin panel settings)
                      MAX_WIDTH = 2000
                      JPEG_QUALITY = 85
                      
                      # Get original dimensions
                      original_width, original_height = img.size
                      original_size_kb = len(file_content) / 1024
                      
                      # Resize if image is too large
                      if original_width > MAX_WIDTH and original_width > 0:
                          # Calculate new height maintaining aspect ratio
                          new_height = int((original_height * MAX_WIDTH) / original_width)
                          img = img.resize((MAX_WIDTH, new_height), Image.Resampling.LANCZOS)
                          print(f"  ↓ Resized from {original_width}x{original_height} to {MAX_WIDTH}x{new_height}")
                      
                      # Convert RGBA to RGB if needed (for JPEG compatibility)
                      if img.mode == 'RGBA':
                          rgb_img = Image.new('RGB', img.size, (255, 255, 255))
                          rgb_img.paste(img, mask=img.split()[3])
                          img = rgb_img
                      
                      # Determine output path
                      file_path = os.path.join(target_dir, file_name)
                      
                      # Save with optimization and compression
                      if file_name.lower().endswith(('.jpg', '.jpeg')):
                          img.save(file_path, 'JPEG', quality=JPEG_QUALITY, optimize=True)
                      elif file_name.lower().endswith('.png'):
                          img.save(file_path, 'PNG', optimize=True)
                      else:
                          # Default to JPEG
                          base_name = os.path.splitext(file_name)[0]
                          file_path = os.path.join(target_dir, f"{base_name}.jpg")
                          img.save(file_path, 'JPEG', quality=JPEG_QUALITY, optimize=True)
                      
                      # Calculate and log compression results
                      compressed_size_kb = os.path.getsize(file_path) / 1024
                      if original_size_kb > 0:
                          compression_ratio = int((1 - compressed_size_kb / original_size_kb) * 100)
                          if compression_ratio > 0:
                              print(f"  ✓ Compressed: {original_size_kb:.1f}KB → {compressed_size_kb:.1f}KB ({compression_ratio}% smaller)")
                          elif compression_ratio < 0:
                              print(f"  ℹ Size increased: {original_size_kb:.1f}KB → {compressed_size_kb:.1f}KB (format conversion)")
                          else:
                              print(f"  ℹ No size change: {compressed_size_kb:.1f}KB")
                      else:
                          print(f"  ℹ Saved: {compressed_size_kb:.1f}KB")
                      
                      downloaded_files.append(os.path.basename(file_path))
                      print(f"  ✓ Saved: {file_path}")
                      
                  except Exception as e:
                      print(f"  ✗ Not a valid image file: {str(e)}")
                      failed_files.append(file_name)
                  
              except Exception as e:
                  print(f"  ✗ Error processing {file_name}: {str(e)}")
                  failed_files.append(file_name)
          
          print(f"\n{'='*60}")
          print(f"Successfully downloaded {len(downloaded_files)} file(s)")
          if failed_files:
              print(f"Failed to download {len(failed_files)} file(s): {', '.join(failed_files)}")
          print(f"{'='*60}")
          
          # Output results
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"file_count={len(downloaded_files)}\n")
              f.write(f"failed_count={len(failed_files)}\n")
              if len(downloaded_files) > 0:
                  f.write(f"status=success\n")
              else:
                  f.write(f"status=no_success\n")
              f.write(f"files={json.dumps(downloaded_files)}\n")
          PYTHON_SCRIPT
      
      - name: Update config.js
        if: steps.download.outputs.status == 'success'
        env:
          CATEGORY: ${{ github.event.client_payload.category || github.event.inputs.category }}
          FILES: ${{ steps.download.outputs.files }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import json
          import re
          
          category = os.environ['CATEGORY']
          new_files = json.loads(os.environ['FILES'])
          
          # Map category names
          category_map = {
              'track': 'track',
              'soccer': 'soccer',
              'football': 'football',
              'basketball': 'basketball',
              'best-of': 'bestOf'
          }
          
          config_key = category_map[category]
          config_path = 'js/config.js'
          
          print(f"Updating config.js for category '{config_key}' with {len(new_files)} file(s)")
          
          # Read current config
          with open(config_path, 'r') as f:
              config_content = f.read()
          
          # Find the images array for this category - updated pattern
          pattern = rf'({config_key}:\s*\{{[^}}]*?images:\s*\[)([^\]]*?)(\s*\])'
          
          if not re.search(pattern, config_content, flags=re.DOTALL):
              print(f"Error: Could not find images array for category '{config_key}'")
              exit(1)
          
          def update_images(match):
              prefix = match.group(1)
              current_images_str = match.group(2)
              suffix = match.group(3)
              
              # Parse existing images
              existing_images = []
              for line in current_images_str.split('\n'):
                  line = line.strip()
                  if line and line.startswith('"'):
                      # Extract filename, handling various quote patterns
                      img = line.strip().strip('",').strip('"').strip()
                      if img and img not in new_files:
                          existing_images.append(img)
              
              # Combine existing and new images (new images first)
              all_images = new_files + existing_images
              
              # Format as JavaScript array
              images_str = '\n' + '\n'.join([f'            "{img}",' for img in all_images]) + '\n        '
              
              return f'{prefix}{images_str}{suffix}'
          
          # Update the config
          try:
              updated_config = re.sub(pattern, update_images, config_content, flags=re.DOTALL)
          except Exception as e:
              print(f"Error updating config: {str(e)}")
              exit(1)
          
          # Write back
          with open(config_path, 'w') as f:
              f.write(updated_config)
          
          print("Config updated successfully")
          PYTHON_SCRIPT
      
      - name: Commit and push changes
        if: steps.download.outputs.status == 'success'
        env:
          CATEGORY: ${{ github.event.client_payload.category || github.event.inputs.category }}
          FILE_COUNT: ${{ steps.download.outputs.file_count }}
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          
          git add images/ js/config.js
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Add $FILE_COUNT image(s) from Google Drive to $CATEGORY"
            git push
            echo "Changes pushed successfully"
          fi
