name: Google Drive Image Sync

on:
  repository_dispatch:
    types: [sync-google-drive-images]
  workflow_dispatch:
    inputs:
      folder_link:
        description: 'Google Drive folder link'
        required: true
        type: string
      category:
        description: 'Category (track/soccer/football/basketball/best-of)'
        required: true
        type: string

permissions:
  contents: write

jobs:
  sync-images:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests Pillow beautifulsoup4
      
      - name: Extract folder ID from link
        id: extract_id
        run: |
          # Extract folder ID from various Google Drive URL formats
          FOLDER_LINK="${{ github.event.client_payload.folder_link || github.event.inputs.folder_link }}"
          echo "Input folder link: $FOLDER_LINK"
          
          # Validate input to prevent command injection
          if [[ ! "$FOLDER_LINK" =~ ^[a-zA-Z0-9_/:.?=-]+$ ]]; then
            echo "Error: Invalid characters in folder link"
            exit 1
          fi
          
          # Pattern 1: https://drive.google.com/drive/folders/FOLDER_ID
          if [[ $FOLDER_LINK =~ /folders/([a-zA-Z0-9_-]+) ]]; then
            FOLDER_ID="${BASH_REMATCH[1]}"
          # Pattern 2: https://drive.google.com/drive/u/0/folders/FOLDER_ID
          elif [[ $FOLDER_LINK =~ /u/[0-9]+/folders/([a-zA-Z0-9_-]+) ]]; then
            FOLDER_ID="${BASH_REMATCH[1]}"
          # Pattern 3: Direct folder ID
          elif [[ $FOLDER_LINK =~ ^[a-zA-Z0-9_-]+$ ]]; then
            FOLDER_ID="$FOLDER_LINK"
          else
            echo "Error: Could not extract folder ID from link"
            exit 1
          fi
          
          # Validate extracted folder ID format
          if [[ ! "$FOLDER_ID" =~ ^[a-zA-Z0-9_-]+$ ]]; then
            echo "Error: Invalid folder ID format"
            exit 1
          fi
          
          echo "folder_id=$FOLDER_ID" >> $GITHUB_OUTPUT
          echo "Extracted folder ID: $FOLDER_ID"
      
      - name: Download images from Google Drive
        id: download
        env:
          FOLDER_ID: ${{ steps.extract_id.outputs.folder_id }}
          CATEGORY: ${{ github.event.client_payload.category || github.event.inputs.category }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import io
          import json
          import re
          import requests
          from bs4 import BeautifulSoup
          from PIL import Image
          from urllib.parse import parse_qs, urlparse, unquote
          
          folder_id = os.environ['FOLDER_ID']
          category = os.environ['CATEGORY']
          
          # Constants for file ID validation and image detection
          MIN_FILE_ID_LENGTH = 25
          MAX_FILE_ID_LENGTH = 44
          FILE_ID_PREFIX_CHECK_LENGTH = 10
          IMAGE_EXTENSIONS = r'jpg|jpeg|png|gif|webp|bmp|JPG|JPEG|PNG|GIF|WEBP|BMP'
          
          # Map category to directory name
          category_map = {
              'track': 'track',
              'soccer': 'soccer',
              'football': 'football',
              'basketball': 'basketball',
              'best-of': 'best-of'
          }
          
          if category not in category_map:
              print(f"Error: Invalid category '{category}'")
              exit(1)
          
          target_dir = f"images/{category_map[category]}"
          os.makedirs(target_dir, exist_ok=True)
          
          print(f"Downloading images from public folder {folder_id} to {target_dir}")
          print("âœ¨ Using FREE public folder access - No credit card or service account required!")
          
          # Function to get files from public Google Drive folder
          def get_public_drive_files(folder_id):
              """Get list of files from a public Google Drive folder by parsing the page data"""
              url = f"https://drive.google.com/drive/folders/{folder_id}"
              
              # Make request with proper headers to get the full page
              headers = {
                  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
                  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                  'Accept-Language': 'en-US,en;q=0.5',
                  'Accept-Encoding': 'gzip, deflate',
                  'Connection': 'keep-alive',
                  'Upgrade-Insecure-Requests': '1'
              }
              
              try:
                  print(f"Fetching folder page: {url}")
                  response = requests.get(url, headers=headers, timeout=30)
                  response.raise_for_status()
                  
                  html_content = response.text
                  files = []
                  
                  # Google Drive embeds data in JavaScript arrays within the HTML
                  # Look for the pattern that contains file information
                  # The data is typically in format: ["fileId","fileName",...]
                  
                  # Method 1: Look for embedded JSON data structures
                  # Drive stores file info in various JS arrays, try to find them
                  # Pattern matches: ["fileId","filename.jpg",...]
                  json_pattern = rf'\[\"([a-zA-Z0-9_-]{{{MIN_FILE_ID_LENGTH},{MAX_FILE_ID_LENGTH}}})\",\"([^\"]+?\.(?:{IMAGE_EXTENSIONS}))\"'
                  matches = re.findall(json_pattern, html_content)
                  
                  if matches:
                      print(f"Found {len(matches)} image file(s) using primary method")
                      seen_ids = set()
                      for file_id, file_name in matches:
                          # Skip duplicates and validate ID format
                          # Google Drive file IDs typically don't have underscores in the first part
                          if file_id not in seen_ids and len(file_id) >= MIN_FILE_ID_LENGTH and '_' not in file_id[:FILE_ID_PREFIX_CHECK_LENGTH]:
                              files.append({
                                  'id': file_id,
                                  'name': file_name
                              })
                              seen_ids.add(file_id)
                              print(f"  - {file_name} (ID: {file_id})")
                  
                  # Method 2: Try alternative pattern if Method 1 didn't work
                  if not files:
                      print("Trying alternative extraction method...")
                      # Look for the key-value pattern where file data might be stored
                      # Pattern matches: ["1...","filename.jpg",...]
                      alt_pattern = rf'\[\"(1[a-zA-Z0-9_-]{{{MIN_FILE_ID_LENGTH-1},{MAX_FILE_ID_LENGTH-1}}})\",\[\"([^\"]+?\.(?:{IMAGE_EXTENSIONS}))\"'
                      alt_matches = re.findall(alt_pattern, html_content, re.IGNORECASE)
                      
                      if alt_matches:
                          print(f"Found {len(alt_matches)} image file(s) using alternative method")
                          seen_ids = set()
                          for file_id, file_name in alt_matches:
                              if file_id not in seen_ids:
                                  files.append({
                                      'id': file_id,
                                      'name': file_name
                                  })
                                  seen_ids.add(file_id)
                                  print(f"  - {file_name} (ID: {file_id})")
                  
                  if not files:
                      print("\nâš ï¸ Could not find files in the folder.")
                      print("This could mean:")
                      print("  1. The folder is empty")
                      print("  2. The folder is not shared publicly ('Anyone with the link' can view)")
                      print("  3. The folder contains no image files")
                      print("  4. Google Drive's HTML structure has changed")
                      print("\nðŸ“ Please verify:")
                      print("  - Right-click the folder in Google Drive")
                      print("  - Click 'Share' â†’ Make sure it says 'Anyone with the link' can VIEW")
                      print("  - Add image files (JPG, PNG, GIF, etc.) to the folder")
                  
                  return files
                  
              except requests.exceptions.RequestException as e:
                  print(f"Error accessing folder: {str(e)}")
                  print("\nMake sure:")
                  print("  1. The folder link is correct")
                  print("  2. The folder is shared as 'Anyone with the link can view'")
                  print("  3. The folder contains image files")
                  print("  4. You have internet connectivity")
                  return []
          
          def download_public_file(file_id, output_path):
              """Download a file from Google Drive using public direct download"""
              # Try multiple download methods
              
              # Method 1: Direct download URL
              download_url = f"https://drive.google.com/uc?export=download&id={file_id}"
              
              headers = {
                  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
              }
              
              try:
                  response = requests.get(download_url, headers=headers, stream=True, timeout=30)
                  
                  # Check content type first before loading entire response
                  content_type = response.headers.get('content-type', '')
                  
                  # Check if we got a confirmation page (large files) - only check if it's HTML
                  if 'text/html' in content_type:
                      # Only load text for HTML responses
                      page_content = response.text
                      if 'confirm=' in page_content or 'download_warning' in page_content:
                          # Extract confirmation token
                          soup = BeautifulSoup(page_content, 'html.parser')
                          confirm_link = soup.find('a', {'id': 'uc-download-link'})
                          
                          if confirm_link and 'href' in confirm_link.attrs:
                              confirm_url = "https://drive.google.com" + confirm_link['href']
                              response = requests.get(confirm_url, headers=headers, stream=True, timeout=30)
                              content_type = response.headers.get('content-type', '')  # Update content type
                  
                  if response.status_code == 200:
                      # Content type already checked above
                      if 'image' in content_type or 'octet-stream' in content_type:
                          return response.content
                      else:
                          # Try to load it as image anyway (some servers don't set correct content-type)
                          return response.content
                  
                  return None
                  
              except Exception as e:
                  print(f"  Error during download: {str(e)}")
                  return None
          
          # Get files from the public folder
          files = get_public_drive_files(folder_id)
          
          if not files:
              print("\n" + "="*60)
              print("NO FILES FOUND")
              print("="*60)
              print("\nTo use this FREE method (no credit card needed):")
              print("1. Right-click your Google Drive folder")
              print("2. Select 'Share' > 'Get link'")
              print("3. Change to 'Anyone with the link' can VIEW")
              print("4. Copy and use that link")
              print("\nâœ¨ This method is 100% free - no Google Cloud account needed!")
              print("="*60)
              
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"file_count=0\n")
                  f.write(f"status=no_files\n")
              exit(0)
          
          print(f"Found {len(files)} file(s) to download")
          
          downloaded_files = []
          failed_files = []
          
          for file_info in files:
              file_id = file_info['id']
              file_name = file_info['name']
              
              print(f"Downloading: {file_name} (ID: {file_id})")
              
              try:
                  # Download file
                  file_content = download_public_file(file_id, target_dir)
                  
                  if not file_content:
                      print(f"  âœ— Could not download file")
                      failed_files.append(file_name)
                      continue
                  
                  # Open with PIL to verify it's a valid image
                  try:
                      img = Image.open(io.BytesIO(file_content))
                      
                      # Image compression settings (match admin panel settings)
                      MAX_WIDTH = 2000
                      JPEG_QUALITY = 85
                      
                      # Get original dimensions
                      original_width, original_height = img.size
                      original_size_kb = len(file_content) / 1024
                      
                      # Resize if image is too large
                      if original_width > MAX_WIDTH and original_width > 0:
                          # Calculate new height maintaining aspect ratio
                          new_height = int((original_height * MAX_WIDTH) / original_width)
                          img = img.resize((MAX_WIDTH, new_height), Image.Resampling.LANCZOS)
                          print(f"  â†“ Resized from {original_width}x{original_height} to {MAX_WIDTH}x{new_height}")
                      
                      # Convert RGBA to RGB if needed (for JPEG compatibility)
                      if img.mode == 'RGBA':
                          rgb_img = Image.new('RGB', img.size, (255, 255, 255))
                          rgb_img.paste(img, mask=img.split()[3])
                          img = rgb_img
                      
                      # Determine output path
                      file_path = os.path.join(target_dir, file_name)
                      
                      # Save with optimization and compression
                      if file_name.lower().endswith(('.jpg', '.jpeg')):
                          img.save(file_path, 'JPEG', quality=JPEG_QUALITY, optimize=True)
                      elif file_name.lower().endswith('.png'):
                          img.save(file_path, 'PNG', optimize=True)
                      else:
                          # Default to JPEG
                          base_name = os.path.splitext(file_name)[0]
                          file_path = os.path.join(target_dir, f"{base_name}.jpg")
                          img.save(file_path, 'JPEG', quality=JPEG_QUALITY, optimize=True)
                      
                      # Calculate and log compression results
                      compressed_size_kb = os.path.getsize(file_path) / 1024
                      if original_size_kb > 0:
                          compression_ratio = int((1 - compressed_size_kb / original_size_kb) * 100)
                          if compression_ratio > 0:
                              print(f"  âœ“ Compressed: {original_size_kb:.1f}KB â†’ {compressed_size_kb:.1f}KB ({compression_ratio}% smaller)")
                          elif compression_ratio < 0:
                              print(f"  â„¹ Size increased: {original_size_kb:.1f}KB â†’ {compressed_size_kb:.1f}KB (format conversion)")
                          else:
                              print(f"  â„¹ No size change: {compressed_size_kb:.1f}KB")
                      else:
                          print(f"  â„¹ Saved: {compressed_size_kb:.1f}KB")
                      
                      downloaded_files.append(os.path.basename(file_path))
                      print(f"  âœ“ Saved: {file_path}")
                      
                  except Exception as e:
                      print(f"  âœ— Not a valid image file: {str(e)}")
                      failed_files.append(file_name)
                  
              except Exception as e:
                  print(f"  âœ— Error processing {file_name}: {str(e)}")
                  failed_files.append(file_name)
          
          print(f"\n{'='*60}")
          print(f"Successfully downloaded {len(downloaded_files)} file(s)")
          if failed_files:
              print(f"Failed to download {len(failed_files)} file(s): {', '.join(failed_files)}")
          print(f"{'='*60}")
          
          # Output results
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"file_count={len(downloaded_files)}\n")
              f.write(f"failed_count={len(failed_files)}\n")
              if len(downloaded_files) > 0:
                  f.write(f"status=success\n")
              else:
                  f.write(f"status=no_success\n")
              f.write(f"files={json.dumps(downloaded_files)}\n")
          PYTHON_SCRIPT
      
      - name: Update config.js
        if: steps.download.outputs.status == 'success'
        env:
          CATEGORY: ${{ github.event.client_payload.category || github.event.inputs.category }}
          FILES: ${{ steps.download.outputs.files }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import json
          import re
          
          category = os.environ['CATEGORY']
          new_files = json.loads(os.environ['FILES'])
          
          # Map category names
          category_map = {
              'track': 'track',
              'soccer': 'soccer',
              'football': 'football',
              'basketball': 'basketball',
              'best-of': 'bestOf'
          }
          
          config_key = category_map[category]
          config_path = 'js/config.js'
          
          print(f"Updating config.js for category '{config_key}' with {len(new_files)} file(s)")
          
          # Read current config
          with open(config_path, 'r') as f:
              config_content = f.read()
          
          # Find the images array for this category - updated pattern
          pattern = rf'({config_key}:\s*\{{[^}}]*?images:\s*\[)([^\]]*?)(\s*\])'
          
          if not re.search(pattern, config_content, flags=re.DOTALL):
              print(f"Error: Could not find images array for category '{config_key}'")
              exit(1)
          
          def update_images(match):
              prefix = match.group(1)
              current_images_str = match.group(2)
              suffix = match.group(3)
              
              # Parse existing images
              existing_images = []
              for line in current_images_str.split('\n'):
                  line = line.strip()
                  if line and line.startswith('"'):
                      # Extract filename, handling various quote patterns
                      img = line.strip().strip('",').strip('"').strip()
                      if img and img not in new_files:
                          existing_images.append(img)
              
              # Combine existing and new images (new images first)
              all_images = new_files + existing_images
              
              # Format as JavaScript array
              images_str = '\n' + '\n'.join([f'            "{img}",' for img in all_images]) + '\n        '
              
              return f'{prefix}{images_str}{suffix}'
          
          # Update the config
          try:
              updated_config = re.sub(pattern, update_images, config_content, flags=re.DOTALL)
          except Exception as e:
              print(f"Error updating config: {str(e)}")
              exit(1)
          
          # Write back
          with open(config_path, 'w') as f:
              f.write(updated_config)
          
          print("Config updated successfully")
          PYTHON_SCRIPT
      
      - name: Validate config.js
        if: steps.download.outputs.status == 'success'
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import re
          
          config_path = 'js/config.js'
          
          print("Validating config.js...")
          
          # Read the config file
          with open(config_path, 'r') as f:
              config_content = f.read()
          
          # Basic validation checks
          errors = []
          
          # Check for duplicate closing braces (common error)
          if re.search(r'\}\s*;\s*\}\s*;', config_content):
              errors.append("Duplicate closing braces detected (}; };)")
          
          # Check for syntax issues
          if config_content.count('const portfolioConfig = {') != 1:
              errors.append("portfolioConfig should be defined exactly once")
          
          if config_content.count('const placeholderImages = [') != 1:
              errors.append("placeholderImages should be defined exactly once")
          
          # Check for each category
          required_categories = ['track', 'soccer', 'football', 'basketball', 'bestOf']
          for category in required_categories:
              if not re.search(rf'{category}:\s*\{{', config_content):
                  errors.append(f"Missing category: {category}")
              
              # Check for images array
              if not re.search(rf'{category}:\s*\{{[^}}]*?images:\s*\[', config_content, re.DOTALL):
                  errors.append(f"Missing images array for category: {category}")
          
          # Check for path traversal attempts
          if '../' in config_content or '..\\' in config_content:
              errors.append("Potential path traversal detected in filenames")
          
          # Check for trailing commas in last array element (can cause issues in some JS engines)
          # This is actually OK in modern JavaScript, but let's check structure
          
          # Validate image extensions
          image_pattern = r'"([^"]+\.(jpg|jpeg|png|gif|bmp|webp|JPEG|JPG|PNG|GIF|BMP|WEBP))"'
          valid_images = re.findall(image_pattern, config_content, re.IGNORECASE)
          
          # Count images found
          print(f"Found {len(valid_images)} image references")
          
          # Report validation results
          if errors:
              print("\nâŒ VALIDATION ERRORS:")
              for error in errors:
                  print(f"  - {error}")
              print("\nConfig validation failed! Please review the errors above.")
              exit(1)
          else:
              print("âœ“ Config validation passed successfully")
          PYTHON_SCRIPT
      
      - name: Commit and push changes
        if: steps.download.outputs.status == 'success'
        env:
          CATEGORY: ${{ github.event.client_payload.category || github.event.inputs.category }}
          FILE_COUNT: ${{ steps.download.outputs.file_count }}
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          
          git add images/ js/config.js
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Add $FILE_COUNT image(s) from Google Drive to $CATEGORY"
            git push
            echo "Changes pushed successfully"
          fi
